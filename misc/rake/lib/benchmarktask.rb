# 
# Benchmarking Task library
# $Id$
# 
# Authors:
# * Michael Granger <ged@faeriemud.org>
# * Mahlon E. Smith <mahlon@martini.nu>
# 

require 'open3'
require 'digest/md5'
require 'rake/tasklib'
require 'misc/rake/svn'
require 'thingfish/client'
require 'thingfish/config'
require 'thingfish/daemon'


module Benchmark
	
	### An object class for encapsulating a single datapoint in a benchmark dataset
	class Datapoint

		### Create a new Datapoint for the given +http_method+ (which should be a 
		### Symbol like :get or :put), +uri+, and +options+ hash. Uses the specified
		### +name+ when used in text or graphical output.
		def initialize( name, http_method, uri, ab_output, options={} )
			@name = name
			@http_method = http_method
			@uri = uri
			@ab_output = ab_output
			@options = options
		
			@times = []
		end


		######
		public
		######
	
		# The name of the datapoint
		attr_reader :name
		
		# The HTTP method of the requests run for the datapoint
		attr_reader :http_method
		
		# The URI of the requests run for the datapoint
		attr_reader :uri
		
		# The statistics that ab generates on stdout
		attr_reader :ab_output
		
		# The options that were used to configure the requests run for the datapoint 
		attr_reader :options


		### Append a row of times output from 'ab'
		def <<( row )
			@times << row
			return self
		end
	end


	### An object class that encapsulates one or more datapoints gathered while running
	### ThingFish in a particular configuration, and which provides methods for 
	### generating output from the datapoints as graphs or text reports.
	class Dataset

		### Create a new Benchmark dataset object with the given name, ThingFish daemon config, 
		### and benchmark config.
		def initialize( name, config, benchmark_config )
			@name = name
			@datapoints = []
			@config = config
			@benchmark_config = benchmark_config

			begin
				require 'gruff'
				@have_gruff = true
			rescue LoadError
				@have_gruff = false
			end
		end


		######
		public
		######
		
		# The name of the dataset
		attr_reader :name

		# The datapoints gathered for the dataset
		attr_reader :datapoints

		# The ThingFish::Config used to configure the ThingFish daemon the dataset was run
		# against
		attr_reader :config

		# Benchmarking config options passed to with_config()
		attr_reader :benchmark_config
		

		### Append a Benchmark::Datapoint to the dataset
		def <<( datapoint )
			@datapoints << datapoint
			return self
		end
	

		### Create pretty graphs using the Gnuplot binary.
		def generate_gnuplot_graphs( outputdir )
			unless gnuplot = which('gnuplot')
				trace "Skipping Gnuplot graph generation: Gnuplot not found in path."
				return
			end
		
			gp_io = open( '|-', 'w+' ) or exec gnuplot
		
			# gp_io.puts
		end


		### Create pretty graphs using the Gruff library.
		def generate_gruff_graphs( outputdir )
			unless @have_gruff
				trace "Skipping Gruff graph generation: Gruff does not appear to be installed."
				return
			end

			@datapoints.each do |name, timedata|
				datasets = timedata.transpose

				g = Gruff::StackedArea.new( 1200 )
				g.theme_keynote
				g.title = "ThingFish Benchmark -- #{name}"
				g.title_font_size = 14
				g.y_axis_increment = 10
				g.y_axis_label = "Time (ms)"
				g.x_axis_label = "%d Requests Over %0.3f seconds" % [
					datasets.first.length - 1,
					(Float( datasets[1][-1] ) - Float( datasets[1][1] )) / 1000000.0
				  ]

				max = 0
				datasets[ 2..5 ].each do |data|
					values = data[1..-1].collect {|i| Integer(i) }
					max += values.max
					g.data( data[0], values )
				end

				g.maximum_value = max
				g.labels = {
					0 => "0",
					(datasets.first.length - 2) => (datasets.first.length - 2).to_s
				}

				graphname = "%s-%s" % [ benchmarkname(), name.gsub(/\W+/, '_') ]
				graph_file = BASEDIR + "#{graphname}-#{@timestamp}.png"
				log "Writing graph to #{graph_file}"
				g.write( graph_file.to_s )
			end
		end
	end


	### A rake task for generating ThingFish benchmarks using 'ab'
	class Task < Rake::Task

		BENCHMARKS_DIR = Pathname.new( 'benchmarks' )

		BENCH_CONFIG_DEFAULTS = {
			:concurrency => 5,
			:count => 300,
		}
		
		AB_PATCH_LOCATION = "https://issues.apache.org/bugzilla/show_bug.cgi?id=44851"


		### Define subordinate tasks for benchmarks before the main task is defined
		def self::define_task( *args, &block )
			task = super

			directory BENCHMARKS_DIR.to_s
			nsname = task.name.gsub( /.*:/, '' )
			desc "Clobber output for the #{nsname} benchmarks"
			task "clobber_#{nsname}" do
				# TODO
			end
			return task
		end


		### Create a new benchmark task
		def initialize( *args )
			super

			@daemon = nil
			@config = nil
			@dataset = nil
			@outputdir = BENCHMARKS_DIR + "r%d" % [get_svn_rev( BASEDIR )]
			@outputdir.mkpath
		end

	
		######
		public
		######

		# The name of the benchmark
		attr_reader :name
	
		# The current dataset being generated by the benchmark
		attr_reader :dataset


		### Execute the task. Note that this is overridden from the base Task class's #execute
		### so it will execute in the context of the task object itself.
		def execute( args )
			if application.options.dryrun
				puts "** Execute (dry run) #{name}"
				return
			end

			if application.options.trace
				puts "** Execute #{name}"
			end

			application.enhance_with_matching_rule(name) if @actions.empty?

			@actions.each do |act|
				self.instance_eval( &act )
			end
		end
	


		#######
		private
		#######

		### Set up both a ThingFish::Config object and a benchmark config hash, and then 
		### run eval the specified block in the context of the task with the config set
		### in the @config instance variable.
		def with_config( configobj, benchmark_config={}, &block )

			trace "Running the %s benchmark with config %p" % [ self.name, configobj ]
			begin
				trace "Using config object 0x%0x" % [ configobj.object_id * 2 ]
				@config = configobj
				@benchmark_config = BENCH_CONFIG_DEFAULTS.merge( benchmark_config )
				
				@dataset = Benchmark::Dataset.new( self.name, @config, @benchmark_config )
				@daemon = ThingFish::Daemon.new( @config )

				trace "Starting configured ThingFish daemon"
				Signal.trap( 'INT'  ) { @daemon.shutdown("Interrupted") }
				Signal.trap( 'TERM' ) { @daemon.shutdown("Terminated") }
				@daemon_thread = @daemon.run
			
				self.instance_eval( &block )
			
				save_dataset()
			ensure
				trace "Clearing out the config objects"
				@daemon.shutdown("Benchmarks done") if @daemon

				@benchmark_config = nil
				@config = nil
				@dataset = nil
			end
		end


		### Process the results into a useful format
		def save_dataset
			savefile = @outputdir + "%s.data" % [ benchmarkname() ]
			savefile.open( File::CREAT|File::WRONLY ) do |fh|
				Marshal.dump( @dataset, fh )
			end
		
			return savefile
		end
	

		### Define a datapoint in the current benchmark for a given config
		def datapoint( name, http_method=:get, uri="/", options={} )
			raise "Not in a config section" unless @config
		
			log "Adding the '#{name}' datapoint"
			trace " ab config '%s %s' on %s port %d: concurrency: %d, iterations: %d" % [
				http_method.to_s.upcase,
				uri,
				@config[:ip],
				@config[:port],
				@benchmark_config[:concurrency],
				@benchmark_config[:count]
			  ]
		
			dpname = name.gsub( /\W+/, "_" ).downcase.sub( /_$/, '' )
			resultsfile = @outputdir + "%s.%s.tsv" % [ benchmarkname(), dpname ]
		
			abprog = which( 'ab' ) or fail "ab: no such file or directory"
			
			# ab capability check
			find_pattern_in_pipe( /-D\s+Send a DELETE request/, abprog, '-h' ) or
				fail "Benchmarks require patched ab, see: #{AB_PATCH_LOCATION}"
		
			ab = [ abprog, '-g', resultsfile.to_s ]

			ab << '-n' << @benchmark_config[:count].to_s       if @benchmark_config[:count]
			ab << '-c' << @benchmark_config[:concurrency].to_s if @benchmark_config[:concurrency]
			ab << '-t' << @benchmark_config[:timed].to_s       if @benchmark_config[:timed]
			
			if @benchmark_config[:headers]
				@benchmark_config[:headers].each do |header, value|
					ab << '-H' << "%s: %s" % [ header, value ]
				end
			end
			
			case http_method
			when :put
				fail "PUT requires an :entity_body" unless options[:entity_body]
				ab << '-u' << options[:entity_body]	
			when :post
				fail "POST requires an :entity_body" unless options[:entity_body]
				ab << '-p' << options[:entity_body]
			when :delete
				ab << '-D'
			when :head
				ab << '-i'
			when :get
			else
				fail "Unsupported http_method in benchmark: %s" % [ http_method ]
			end
			
			ab.push( "#{@config.ip}:#{@config.port}#{uri}" )

			trace "Running command: #{ab.join(' ')}"
			ab_output = []
			Open3.popen3( *ab ) do |stdin, stdout, stderr|
				trace "In the open3 block"
				stdin.close
				trace( stderr.gets ) until stderr.eof?
				until stdout.eof?
					output_line = stdout.gets
					ab_output << output_line if output_line =~ /:\s+\w/
					trace( output_line ) 
				end
			end
			trace( "ab exited with code: %d" % [ $? ] )
		
			datapoint = Benchmark::Datapoint.new( name, http_method, uri, ab_output, options )
			resultsfile.each_line do |line|
				next if line =~ /^starttime/
				datapoint << line.chomp.split( /\t/ )[2..5]			
			end
		
			@dataset << datapoint
		end
	
	
		### Create a ThingFish::Client object that will talk to the configured ThingFish daemon
		### and yield it to the block to do any necessary preparation for the benchmark. The
		### return value from the block is returned.
		def prep
			raise "Not in a config section" unless @config
		
			log "Creating a client object for benchmark prep"
			client = ThingFish::Client.new( "http://#{@config.ip}:#{@config.port}/" )
			return yield( client )
		end
	
	
		### Return a normalized version of the benchmark name suitable for use in path names.
		def benchmarkname
			return self.name[ /.*:(.*)$/, 1 ]
		end
	end # class Task

end # module Benchmark


### Declare a new Benchmark task.
### 
### Example:
### 
### benchmark :plain do
###   # ...stuff...
### 
### end
### 
def benchmark( *args, &block )
	task = Benchmark::Task.define_task( *args, &block )
end


